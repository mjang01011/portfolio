{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22eb601e-a501-40c1-8de2-ac3d7a9a2f5d",
   "metadata": {},
   "source": [
    "The purpose of the notebook is to demonstrate quantization of a deep learning model (ResNet in this example). Quantization is a method to reduce the number of bits used to represent each parameter in the model. There are three main purposes of quantization:\n",
    "1. Reduce Model Size\n",
    "Memory Efficiency: Instead of using 32-bit floating-point numbers (FP32), quantization typically reduces this to 16-bit floating-point (FP16). This leads to significant reductions in the model's memory usage.\n",
    "Storage Savings: Smaller models require less storage space, which is beneficial for deploying models on devices with limited memory, such as embedded systems.\n",
    "2. Improve Computational Efficiency\n",
    "Faster Inference: Operations involving lower-bit integers (e.g., 8-bit integers) are typically faster to execute than those involving floating-point numbers. Hardware accelerators like CPUs, GPUs, and specialized AI processors often have optimized instructions for integer arithmetic, making quantized models more efficient in terms of computation.\n",
    "Reduced Bandwidth: Lower precision data requires less bandwidth, which can be advantageous for data transfer and network communication in distributed systems or edge devices.\n",
    "3. Lower Power Consumption\n",
    "Energy Efficiency: Quantized operations consume less power compared to their floating-point counterparts.\n",
    "Hardware Utilization: Many modern processors are designed to handle lower-precision arithmetic more efficiently, leading to lower overall power usage during model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2390a954-f45d-4ace-bbe7-057312401120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f69485a4-5f13-45ca-950f-aae447bd7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "    self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    self.downsample = None\n",
    "    if stride==2:\n",
    "      self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "\n",
    "  def forward(self, x):\n",
    "    res = x\n",
    "    # print(f\"RES Shape: {res.shape}\")\n",
    "    out = self.conv1(x)\n",
    "    # print(f\"CONV1 Shape: {out.shape}\")\n",
    "    out = self.bn1(out)\n",
    "    out = F.relu(out)\n",
    "    out = self.conv2(out)\n",
    "    # print(f\"CONV2 Shape: {out.shape}\")\n",
    "    out = self.bn2(out)\n",
    "    if self.downsample is not None:\n",
    "      res = self.downsample(x)\n",
    "      # print(f\"NEW RES Shape: {res.shape}\")\n",
    "\n",
    "    out += res\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "class ResNet20(nn.Module):\n",
    "  def __init__(self, resblock, n=3):\n",
    "    super(ResNet20, self).__init__()\n",
    "    self.n = n\n",
    "    self.conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(16)\n",
    "    self.avgpool = nn.AvgPool2d(8)\n",
    "    self.fc1   = nn.Linear(64, 10)\n",
    "\n",
    "    self.layer1 = self.create_layer(resblock, 16, 16, stride=1)\n",
    "    self.layer2 = self.create_layer(resblock, 16, 32, stride=2)\n",
    "    self.layer3 = self.create_layer(resblock, 32, 64, stride=2)\n",
    "\n",
    "  def create_layer(self, resblock, in_channels, out_channels, stride):\n",
    "    layers = nn.ModuleList()\n",
    "    layers.append(resblock(in_channels, out_channels, stride))\n",
    "    for i in range(self.n-1):\n",
    "      layers.append(resblock(out_channels, out_channels, stride=1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = F.relu(out)\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.avgpool(out)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.fc1(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190f02de-d673-42a2-80c6-a850baae30b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "     ResidualBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "    ResidualBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "    ResidualBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 32, 16, 16]           4,640\n",
      "      BatchNorm2d-19           [-1, 32, 16, 16]              64\n",
      "           Conv2d-20           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
      "           Conv2d-22           [-1, 32, 16, 16]             544\n",
      "    ResidualBlock-23           [-1, 32, 16, 16]               0\n",
      "           Conv2d-24           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-25           [-1, 32, 16, 16]              64\n",
      "           Conv2d-26           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-27           [-1, 32, 16, 16]              64\n",
      "    ResidualBlock-28           [-1, 32, 16, 16]               0\n",
      "           Conv2d-29           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-30           [-1, 32, 16, 16]              64\n",
      "           Conv2d-31           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-32           [-1, 32, 16, 16]              64\n",
      "    ResidualBlock-33           [-1, 32, 16, 16]               0\n",
      "           Conv2d-34             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
      "           Conv2d-36             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-37             [-1, 64, 8, 8]             128\n",
      "           Conv2d-38             [-1, 64, 8, 8]           2,112\n",
      "    ResidualBlock-39             [-1, 64, 8, 8]               0\n",
      "           Conv2d-40             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-41             [-1, 64, 8, 8]             128\n",
      "           Conv2d-42             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-44             [-1, 64, 8, 8]               0\n",
      "           Conv2d-45             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-46             [-1, 64, 8, 8]             128\n",
      "           Conv2d-47             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-49             [-1, 64, 8, 8]               0\n",
      "        AvgPool2d-50             [-1, 64, 1, 1]               0\n",
      "           Linear-51                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 273,066\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.63\n",
      "Params size (MB): 1.04\n",
      "Estimated Total Size (MB): 4.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ResNet20(ResidualBlock).to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b6da2a-fa61-47fb-9441-93c7e3a28335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"resnet.pth\")['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453d7b8-363c-4fbc-a94e-ac9635ad3097",
   "metadata": {},
   "source": [
    "Fixed-point quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ad5df-6240-467f-82bf-4adc9df05191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1d5830-200a-4d2e-8302-cd56c041b713",
   "metadata": {},
   "source": [
    "Quantize pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602f18a-8076-4dd3-adad-d13a8fdd0bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9847972d-b823-4c2a-9afa-19aa1738da44",
   "metadata": {},
   "source": [
    "Symmetric quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf761f92-61d7-4cee-9f4a-edcb0f54ab0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e71cbd-fc5a-4919-a078-89b6705fa4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54a61f-ca01-4c9c-ac99-79139bdd3ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be8994-659f-4d25-8a60-7cfdbefd6226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfff074-cf5f-4ad5-b755-0d2ca693fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e7e71-68f5-4969-ae54-e5a9208d0f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abe8e9-10ec-491e-aa52-11cb8c89f4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
